#FILTERING FOR ALL CHANNELS AND STORING RESULTS FOR LATER ACCESS

import numpy as np
import netCDF4
import glob
import os
import re

path = os.path.expanduser("~/Desktop/MEPED POES NOAA15")

ifiles_00 = sorted(glob.glob(os.path.join(path, "POES_combinedSpectrum_n15_00_*.nc")))
ifiles_90 = sorted(glob.glob(os.path.join(path, "POES_combinedSpectrum_n15_90_*.nc")))

if not ifiles_00 or not ifiles_90:
    print(f"Error: No NetCDF files found. Check path and patterns.")
    print(f"Path searched: {path}")
    exit()

if len(ifiles_00) != len(ifiles_90):
    print(f"Warning: Mismatch in file counts: {len(ifiles_00)} (00deg) vs {len(ifiles_90)} (90deg).")
    print("Processing pairs based on sorted order. Ensure files correspond correctly.")

# --- Dictionary to store processed flag_and_time_arrays ---
processed_data_arrays = {}

for i, (file_00_path, file_90_path) in enumerate(zip(ifiles_00, ifiles_90), start=1):
    print(f"Processing File Pair {i}:")
    print(f"  00-degree file: {os.path.basename(file_00_path)}")
    print(f"  90-degree file: {os.path.basename(file_90_path)}")

    # Searches file path for the date and saves it to a string array for the output filename

    filepath = file_00_path
    pattern = r"\d{8}"  # match phone number format
    
    result = re.search(pattern, filepath)  # search pattern
    
    if result:
        Filename_start_index = result.start()  # match start index
        filename_for_output = file_00_path[Filename_start_index:Filename_start_index+8]
    else:
        print("Filename Issue")

    try:
        with netCDF4.Dataset(file_00_path) as d0, netCDF4.Dataset(file_90_path) as d9:
            l_values = d0.variables['lValue'][:]
            relative_times_all = d0.variables['rtime'][:]
            counts_00_all_channels_data = d0.variables['EOcounts_corrected'][:]
            counts_90_all_channels_data = d9.variables['EOcounts_corrected'][:]

    except FileNotFoundError:
        print(f"  Error: One or both files in pair {i} not found. Skipping.")
        print("-" * 40)
        continue
    except KeyError as e:
        print(f"  Error: Variable {e} not found in one of the files. Skipping pair {i}.")
        print("-" * 40)
        continue
    except Exception as e:
        print(f"  An unexpected error occurred while reading files: {e}. Skipping pair {i}.")
        print("-" * 40)
        continue

    if counts_00_all_channels_data.ndim == 1:
        num_channels = 1
    elif counts_00_all_channels_data.ndim > 1:
        num_channels = counts_00_all_channels_data.shape[1]
        if counts_90_all_channels_data.ndim <= 1 or counts_90_all_channels_data.shape[1] != num_channels:
            print(f"  Error: Mismatch in number of channels or dimensions between 00-deg and 90-deg files for pair {i}.")
            print(f"  00-deg shape: {counts_00_all_channels_data.shape}, 90-deg shape: {counts_90_all_channels_data.shape}")
            print("-" * 40)
            continue
    else:
        print(f"  Error: Unexpected dimensions for EOcounts_corrected in 00-deg file for pair {i}. Shape: {counts_00_all_channels_data.shape}")
        print("-" * 40)
        continue

    l_gt_5_mask = l_values > 5

    if not np.any(l_gt_5_mask):
        print(f"  File Pair {i}: No data points found with L > 5 (applies to all channels).")
        print("-" * 40)
        continue

    relative_times_filtered = relative_times_all[l_gt_5_mask]

    if relative_times_filtered.size == 0:
        print(f"  File Pair {i}: No data points remain after L > 5 filtering for time alignment (applies to all channels). Skipping.")
        print("-" * 40)
        continue

    for channel_idx in range(num_channels):
        print(f"\n  --- Processing Energy Channel {channel_idx} ---")

        if num_channels == 1 and counts_00_all_channels_data.ndim == 1:
            current_counts_00 = counts_00_all_channels_data
            current_counts_90 = counts_90_all_channels_data
        else:
            current_counts_00 = counts_00_all_channels_data[:, channel_idx]
            current_counts_90 = counts_90_all_channels_data[:, channel_idx]
        
        counts_00_filtered = current_counts_00[l_gt_5_mask]
        counts_90_filtered = current_counts_90[l_gt_5_mask]

        with np.errstate(divide='ignore', invalid='ignore'):
            ratio_00_over_90 = counts_00_filtered / counts_90_filtered
            event_flags = (ratio_00_over_90 > 2).astype(int)

        if event_flags.size > 0 and relative_times_filtered.size > 0 and event_flags.size == relative_times_filtered.size:
            flag_and_time_array = np.column_stack((event_flags, relative_times_filtered))
            # --- Store the array instead of printing it fully ---
            processed_data_arrays[(i, channel_idx)] = flag_and_time_array
            print(f"    Data for Channel {channel_idx} (Pair {i}) processed and stored.")
        else:
            print(f"    Skipping Channel {channel_idx} for File Pair {i} due to empty or mismatched arrays after filtering.")
            print(f"    event_flags size: {event_flags.size}, relative_times_filtered size: {relative_times_filtered.size}")
            continue # Skip to the next channel if data is problematic for stacking

        num_condition_met = np.sum(event_flags)
        print(f"    Number of instances for Channel {channel_idx} where 00deg_counts / 90deg_counts > 2 (L > 5): {num_condition_met}")
        print(f"    Total data points for Channel {channel_idx} after L > 5 filtering: {len(event_flags)}")

        from netcdf_writer import netcdf_writer
        netcdf_writer(relative_times_filtered, flag_and_time_array, ratio_00_over_90, counts_00_filtered, counts_90_filtered, filename_for_output)
        
        
    print("-" * 40)

print("Processing complete.")

print("\n" + "="*50)
print("ACCESSING STORED DATA EXAMPLE")
print("="*50)

example_pair_to_access = 1
example_channel_to_access = 0
data_key = (example_pair_to_access, example_channel_to_access)

if data_key in processed_data_arrays:
    print(f"\nAccessing stored data for File Pair {example_pair_to_access}, Channel {example_channel_to_access}:")
    retrieved_array = processed_data_arrays[data_key]
    print(f"  Array shape: {retrieved_array.shape}")
    print(f"  First 5 rows of the array:\n{retrieved_array[:5, :]}")
    
else:
    print(f"\nNo data found or stored for File Pair {example_pair_to_access}, Channel {example_channel_to_access}.")
    print("This could be due to an error during its processing, or no data points meeting the criteria.")

print("\nAvailable keys in processed_data_arrays:")
if processed_data_arrays:
    for key in processed_data_arrays.keys():
        print(f"  {key} -> array shape: {processed_data_arrays[key].shape}")
else:
    print("  No data was stored.")
